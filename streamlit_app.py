"""
Vietnamese Sentiment Assistant
S·ª≠ d·ª•ng PhoBERT qua pipeline sentiment-analysis ƒë·ªÉ ph√¢n lo·∫°i c·∫£m x√∫c ti·∫øng Vi·ªát.
"""

import os
import re
import sqlite3
from datetime import datetime
from typing import List, Dict, Optional

import streamlit as st
from transformers import pipeline

# Constants
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "sentiments.db")
MODEL_NAME = "wonrax/phobert-base-vietnamese-sentiment"


def get_db_connection():
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn


def init_db():
    """
    Kh·ªüi t·∫°o database SQLite v·ªõi b·∫£ng sentiments.
    Theo y√™u c·∫ßu: id, text, sentiment, timestamp (ISO string YYYY-MM-DD HH:MM:SS)
    T·ª± ƒë·ªông migrate schema n·∫øu database c≈© c√≥ schema kh√°c.
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        
        # Ki·ªÉm tra xem b·∫£ng c√≥ t·ªìn t·∫°i kh√¥ng
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='sentiments'")
        table_exists = cursor.fetchone()
        
        if table_exists:
            # Ki·ªÉm tra schema hi·ªán t·∫°i
            cursor.execute("PRAGMA table_info(sentiments)")
            columns_info = cursor.fetchall()
            column_names = [col[1] for col in columns_info]
            
            # N·∫øu schema c≈© (kh√¥ng c√≥ timestamp ho·∫∑c c√≥ text_input/created_at), migrate
            if 'timestamp' not in column_names or 'text' not in column_names:
                # X√≥a b·∫£ng c≈© v√† t·∫°o l·∫°i v·ªõi schema m·ªõi
                conn.execute("DROP TABLE IF EXISTS sentiments")
                conn.commit()
                table_exists = False
        
        # T·∫°o b·∫£ng m·ªõi v·ªõi schema ƒë√∫ng (ho·∫∑c t·∫°o n·∫øu ch∆∞a t·ªìn t·∫°i)
        if not table_exists:
            conn.execute(
                """
                CREATE TABLE sentiments (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    text TEXT NOT NULL,
                    sentiment TEXT NOT NULL,
                    timestamp TEXT NOT NULL
                )
                """
            )
            conn.commit()
        else:
            # ƒê·∫£m b·∫£o b·∫£ng c√≥ ƒë√∫ng schema (CREATE IF NOT EXISTS)
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS sentiments (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    text TEXT NOT NULL,
                    sentiment TEXT NOT NULL,
                    timestamp TEXT NOT NULL
                )
                """
            )
            conn.commit()


def save_history(text: str, sentiment: str):
    """
    L∆∞u l·ªãch s·ª≠ ph√¢n lo·∫°i v√†o database.
    S·ª≠ d·ª•ng parameterized queries ƒë·ªÉ tr√°nh SQL injection.
    Timestamp format: YYYY-MM-DD HH:MM:SS (ISO string)
    
    Args:
        text: C√¢u ƒë√£ nh·∫≠p
        sentiment: Nh√£n c·∫£m x√∫c (POSITIVE/NEUTRAL/NEGATIVE)
    """
    # T·∫°o timestamp theo format ISO: YYYY-MM-DD HH:MM:SS
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    with get_db_connection() as conn:
        # S·ª≠ d·ª•ng parameterized queries ƒë·ªÉ tr√°nh SQL injection
        conn.execute(
            """
            INSERT INTO sentiments (text, sentiment, timestamp)
            VALUES (?, ?, ?)
            """,
            (text, sentiment, timestamp),
        )
        conn.commit()


def fetch_history(limit: int = 50) -> List[Dict]:
    """
    L·∫•y l·ªãch s·ª≠ ph√¢n lo·∫°i t·ª´ database.
    Theo y√™u c·∫ßu: gi·ªõi h·∫°n 50 b·∫£n ghi m·ªõi nh·∫•t, ORDER BY timestamp DESC.
    
    Args:
        limit: S·ªë l∆∞·ª£ng b·∫£n ghi c·∫ßn l·∫•y (m·∫∑c ƒë·ªãnh 50)
        
    Returns:
        Danh s√°ch dictionary ch·ª©a th√¥ng tin l·ªãch s·ª≠
    """
    with get_db_connection() as conn:
        # S·ª≠ d·ª•ng parameterized queries v√† ORDER BY timestamp DESC LIMIT 50
        rows = conn.execute(
            """
            SELECT * FROM sentiments 
            ORDER BY timestamp DESC 
            LIMIT ?
            """,
            (limit,),
        ).fetchall()
        return [
            {
                "C√¢u nh·∫≠p": row["text"],
                "K·∫øt qu·∫£": map_sentiment_to_vietnamese(row["sentiment"]),  # Hi·ªÉn th·ªã ti·∫øng Vi·ªát
                "Sentiment": row["sentiment"],  # Gi·ªØ format POSITIVE/NEUTRAL/NEGATIVE ƒë·∫ßy ƒë·ªß
                "Th·ªùi gian": row["timestamp"],  # Format: YYYY-MM-DD HH:MM:SS
            }
            for row in rows
        ]


# Text normalization dictionary
# L∆∞u √Ω: Th·ª© t·ª± quan tr·ªçng - c·ª•m t·ª´ d√†i h∆°n ph·∫£i ƒë∆∞·ª£c x·ª≠ l√Ω tr∆∞·ªõc
COMMON_REPLACEMENTS = {
    # C·ª•m t·ª´ c·∫£m x√∫c ƒë·∫∑c bi·ªát (x·ª≠ l√Ω tr∆∞·ªõc)
    "bu·ªìn c∆∞·ªùi": "h√†i h∆∞·ªõc",  # "bu·ªìn c∆∞·ªùi" = funny (positive), kh√¥ng ph·∫£i bu·ªìn + c∆∞·ªùi
    "buon cuoi": "h√†i h∆∞·ªõc",
    "bu·ªìn cu·ªùi": "h√†i h∆∞·ªõc",
    
    # T·ª´ vi·∫øt t·∫Øt th√¥ng th∆∞·ªùng
    "rat": "r·∫•t",
    "hok": "kh√¥ng",
    "ko": "kh√¥ng",
    "k": "kh√¥ng",
    "khong": "kh√¥ng",
    "dc": "ƒë∆∞·ª£c",
    "duoc": "ƒë∆∞·ª£c",
    "bt": "b√¨nh th∆∞·ªùng",
    "oke": "ok",
    "ok": "ok",
    "vs": "v·ªõi",
    "hong": "kh√¥ng",
    "b√πn": "bu·ªìn",
}


def normalize_text(text: str) -> str:
    """
    Chu·∫©n h√≥a vƒÉn b·∫£n ti·∫øng Vi·ªát: x·ª≠ l√Ω vi·∫øt t·∫Øt, thi·∫øu d·∫•u, c·ª•m t·ª´ ƒë·∫∑c bi·ªát.
    
    Args:
        text: VƒÉn b·∫£n ƒë·∫ßu v√†o
        
    Returns:
        VƒÉn b·∫£n ƒë√£ chu·∫©n h√≥a
    """
    cleaned = text.strip().lower()
    
    # X·ª≠ l√Ω c·ª•m t·ª´ ƒë·∫∑c bi·ªát tr∆∞·ªõc (kh√¥ng d√πng word boundary ƒë·ªÉ match c·ª•m t·ª´)
    # V√≠ d·ª•: "bu·ªìn c∆∞·ªùi" -> "h√†i h∆∞·ªõc" (t√≠ch c·ª±c)
    special_phrases = {
        "bu·ªìn c∆∞·ªùi": "h√†i h∆∞·ªõc",
        "buon cuoi": "h√†i h∆∞·ªõc",
        "bu·ªìn cu·ªùi": "h√†i h∆∞·ªõc",
    }
    for phrase, replacement in special_phrases.items():
        cleaned = cleaned.replace(phrase, replacement)
    
    # X·ª≠ l√Ω c√°c t·ª´ ƒë∆°n l·∫ª v·ªõi word boundary
    for src, tgt in COMMON_REPLACEMENTS.items():
        # B·ªè qua c√°c c·ª•m t·ª´ ƒë√£ x·ª≠ l√Ω ·ªü tr√™n
        if src not in special_phrases:
            cleaned = re.sub(rf"\b{re.escape(src)}\b", tgt, cleaned)
    
    return cleaned


def get_sentiment_label(label: str, score: float) -> str:
    """
    Chuy·ªÉn ƒë·ªïi label t·ª´ model sang POSITIVE/NEUTRAL/NEGATIVE ƒë·∫ßy ƒë·ªß.
    Gi·ªØ nguy√™n logic c≈© - ch·ªâ map label, kh√¥ng thay ƒë·ªïi d·ª±a tr√™n score.
    
    Args:
        label: Label t·ª´ model (LABEL_0, LABEL_1, LABEL_2 ho·∫∑c POSITIVE/NEGATIVE/NEUTRAL)
        score: ƒê·ªô tin c·∫≠y c·ªßa prediction (kh√¥ng d√πng ƒë·ªÉ thay ƒë·ªïi k·∫øt qu·∫£)
        
    Returns:
        Label chu·∫©n ƒë·∫ßy ƒë·ªß: POSITIVE, NEUTRAL, ho·∫∑c NEGATIVE
    """
    # Mapping t·ª´ label model sang POSITIVE/NEUTRAL/NEGATIVE ƒë·∫ßy ƒë·ªß
    # X·ª≠ l√Ω nhi·ªÅu format c√≥ th·ªÉ c√≥ t·ª´ model
    mapping = {
        "LABEL_0": "NEGATIVE",
        "LABEL_1": "NEUTRAL", 
        "LABEL_2": "POSITIVE",
        "NEGATIVE": "NEGATIVE",
        "NEUTRAL": "NEUTRAL",
        "POSITIVE": "POSITIVE",
        "negative": "NEGATIVE",
        "neutral": "NEUTRAL",
        "positive": "POSITIVE",
        "NEG": "NEGATIVE",
        "POS": "POSITIVE",
        "neg": "NEGATIVE",
        "pos": "POSITIVE",
    }
    
    # N·∫øu label r·ªóng ho·∫∑c kh√¥ng t√¨m th·∫•y, ki·ªÉm tra score ƒë·ªÉ quy·∫øt ƒë·ªãnh
    if not label or label not in mapping:
        # N·∫øu kh√¥ng t√¨m th·∫•y trong mapping, th·ª≠ parse t·ª´ label string
        label_upper = label.upper() if label else ""
        if "POS" in label_upper or "T√çCH C·ª∞C" in label_upper or "TICH CUC" in label_upper:
            return "POSITIVE"
        elif "NEG" in label_upper or "TI√äU C·ª∞C" in label_upper or "TIEU CUC" in label_upper:
            return "NEGATIVE"
        elif "NEU" in label_upper or "TRUNG T√çNH" in label_upper or "TRUNG TINH" in label_upper:
            return "NEUTRAL"
        else:
            # M·∫∑c ƒë·ªãnh tr·∫£ v·ªÅ NEUTRAL n·∫øu kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c
            return "NEUTRAL"
    
    # Gi·ªØ nguy√™n k·∫øt qu·∫£ t·ª´ model, ch·ªâ ƒë·∫£m b·∫£o format ƒë·∫ßy ƒë·ªß
    return mapping.get(label, "NEUTRAL")


def map_sentiment_to_vietnamese(sentiment: str) -> str:
    """
    Chuy·ªÉn ƒë·ªïi sentiment (POSITIVE/NEUTRAL/NEGATIVE) sang ti·∫øng Vi·ªát ƒë·ªÉ hi·ªÉn th·ªã.
    
    Args:
        sentiment: POSITIVE, NEUTRAL, ho·∫∑c NEGATIVE
        
    Returns:
        Label ti·∫øng Vi·ªát t∆∞∆°ng ·ª©ng
    """
    mapping = {
        "POSITIVE": "T√≠ch c·ª±c",
        "NEUTRAL": "Trung t√≠nh",
        "NEGATIVE": "Ti√™u c·ª±c",
    }
    return mapping.get(sentiment, sentiment)


# Danh s√°ch t·ª´ c·∫£m x√∫c ƒë∆∞·ª£c ph√©p nh·∫≠p 1 t·ª´
EMOTION_WORDS = {
    "vui", "bu·ªìn", "ch√°n", "c∆∞·ªùi", "buon", "chan", "cuoi",
    "vui v·∫ª", "bu·ªìn b√£", "ch√°n n·∫£n", "c∆∞·ªùi vui",
    "h·∫°nh ph√∫c", "t·ª©c gi·∫≠n", "s·ª£ h√£i", "ng·∫°c nhi√™n",
    "y√™u", "gh√©t", "th√≠ch", "kh√¥ng th√≠ch"
}


@st.cache_resource(show_spinner=True)
def load_classifier():
    """
    T·∫£i model PhoBERT qua pipeline sentiment-analysis.
    Model ƒë∆∞·ª£c cache ƒë·ªÉ kh√¥ng t·∫£i l·∫°i m·ªói l·∫ßn ch·∫°y.
    
    Returns:
        Pipeline sentiment-analysis ƒë√£ ƒë∆∞·ª£c load
    """
    return pipeline(
        "sentiment-analysis",
        model=MODEL_NAME,
        device=-1,  # CPU; d√πng 0 n·∫øu c√≥ GPU
    )


def main():
    """H√†m ch√≠nh c·ªßa ·ª©ng d·ª•ng Streamlit."""
    st.set_page_config(
        page_title="Vietnamese Sentiment Assistant",
        page_icon="üòä",
        layout="centered"
    )
    st.title("Tr·ª£ l√Ω ph√¢n lo·∫°i c·∫£m x√∫c ti·∫øng Vi·ªát")
    #st.markdown("**S·ª≠ d·ª•ng PhoBERT qua pipeline sentiment-analysis**")
    #st.caption("Model: `wonrax/phobert-base-vietnamese-sentiment`")

    init_db()
    classifier = load_classifier()

    text_input = st.text_area("Nh·∫≠p c√¢u ti·∫øng Vi·ªát", height=150, placeholder="V√≠ d·ª•: H√¥m nay t√¥i r·∫•t vui")
    col1, col2 = st.columns([1, 2])

    with col1:
        run_btn = st.button("Ph√¢n lo·∫°i", use_container_width=True, type="primary")

    error_box = st.empty()
    result_box = st.empty()

    if run_btn:
        error_box.empty()
        result_box.empty()

        # ============================================
        # INPUT: ƒê·∫ßu v√†o - C√¢u ti·∫øng Vi·ªát
        # ============================================
        text = (text_input or "").strip()
        
        # ============================================
        # COMPONENT 3: H·ª£p nh·∫•t & x·ª≠ l√Ω l·ªói (Validation)
        # Ki·ªÉm tra ƒë·∫ßu v√†o h·ª£p l·ªá
        # ============================================
        # Ki·ªÉm tra 1: Kh√¥ng c√≥ n·ªôi dung
        if not text:
            error_box.error("‚ö†Ô∏è Vui l√≤ng nh·∫≠p c√¢u c·∫ßn ph√¢n t√≠ch!")
            return
        
        # Ki·ªÉm tra 2: ƒê·∫øm s·ªë t·ª´ v√† ki·ªÉm tra t·ª´ c·∫£m x√∫c
        words = text.split()
        word_count = len([w for w in words if w.strip()])  # ƒê·∫øm t·ª´ kh√¥ng r·ªóng
        
        if word_count < 2:
            # N·∫øu ch·ªâ c√≥ 1 t·ª´, ki·ªÉm tra xem c√≥ ph·∫£i t·ª´ c·∫£m x√∫c kh√¥ng
            if word_count == 1:
                single_word = text.strip().lower()
                # Ki·ªÉm tra xem t·ª´ n√†y c√≥ trong danh s√°ch t·ª´ c·∫£m x√∫c kh√¥ng
                if single_word not in EMOTION_WORDS:
                    error_box.error("‚ö†Ô∏è Vui l√≤ng nh·∫≠p √≠t nh·∫•t 2 t·ª´ ho·∫∑c m·ªôt t·ª´ c·∫£m x√∫c! V√≠ d·ª•: 'T√¥i vui', 'H√¥m nay t√¥i r·∫•t vui', ho·∫∑c 'vui', 'bu·ªìn', 'ch√°n', 'c∆∞·ªùi'")
                    return
                # N·∫øu l√† t·ª´ c·∫£m x√∫c, cho ph√©p ti·∫øp t·ª•c
            else:
                error_box.error("‚ö†Ô∏è Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß c√¢u c√≥ √≠t nh·∫•t 2 t·ª´!")
                return
        
        # Ki·ªÉm tra 3: ƒê·ªô d√†i t·ªëi thi·ªÉu
        if len(text) < 2:
            error_box.error("‚ö†Ô∏è C√¢u qu√° ng·∫Øn, vui l√≤ng nh·∫≠p c√¢u ƒë·∫ßy ƒë·ªß h∆°n!")
            return
        
        # ============================================
        # COMPONENT 1: Ti·ªÅn x·ª≠ l√Ω (Preprocessing)
        # Chu·∫©n h√≥a c√¢u ti·∫øng Vi·ªát
        # ============================================
        normalized = normalize_text(text)
        
        # ============================================
        # COMPONENT 2: Ph√¢n lo·∫°i c·∫£m x√∫c (Sentiment Analysis)
        # S·ª≠ d·ª•ng Transformer pipeline ƒë·ªÉ ph√¢n lo·∫°i
        # ============================================
        try:
            with st.spinner("ƒêang ph√¢n t√≠ch..."):
                res = classifier(normalized)
                
                # X·ª≠ l√Ω k·∫øt qu·∫£ t·ª´ pipeline
                if isinstance(res, list):
                    if res:
                        res = res[0]
                    else:
                        raise ValueError("Kh√¥ng nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ t·ª´ model!")
                
                # L·∫•y label v√† score t·ª´ model
                label = res.get("label", "")
                score = float(res.get("score", 0.0))
                
                # Chuy·ªÉn ƒë·ªïi label sang format POSITIVE/NEUTRAL/NEGATIVE
                sentiment = get_sentiment_label(label, score)
                
        except Exception as e:
            # COMPONENT 3: X·ª≠ l√Ω l·ªói
            error_box.error(f"L·ªói khi ph√¢n t√≠ch: {str(e)}")
            return
        
        # ============================================
        # COMPONENT 3: H·ª£p nh·∫•t & x·ª≠ l√Ω l·ªói (Validation)
        # T·∫°o dictionary output theo ƒë√∫ng format y√™u c·∫ßu
        # ============================================
        result_dict = {
            "text": text,
            "sentiment": sentiment
        }
        
        # ============================================
        # CORE ENGINE: L∆∞u & hi·ªÉn th·ªã
        # ============================================
        # L∆∞u v√†o database (ch·ªâ l∆∞u text v√† sentiment theo y√™u c·∫ßu)
        save_history(text=text, sentiment=sentiment)
        
        # Chuy·ªÉn sang ti·∫øng Vi·ªát ƒë·ªÉ hi·ªÉn th·ªã
        vietnamese_label = map_sentiment_to_vietnamese(sentiment)
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        color = "#10b981" if sentiment == "POSITIVE" else "#ef4444" if sentiment == "NEGATIVE" else "#6b7280"
        icon = "üòä" if sentiment == "POSITIVE" else "üòû" if sentiment == "NEGATIVE" else "üòê"
        
        result_box.markdown(
            f"<div style='padding:12px;border-radius:10px;background:#f3f4f6;'>"
            f"<div style='font-size:18px;font-weight:700;color:{color};'>{icon} {vietnamese_label} ({sentiment})</div>"
            f"<div style='margin-top:4px;'>ƒê·ªô tin c·∫≠y: {round(score*100, 2)}%</div>"
            f"<div style='margin-top:4px;color:#374151;'>C√¢u (chu·∫©n h√≥a): {normalized}</div>"
            f"</div>",
            unsafe_allow_html=True, 
        )
        
        # Hi·ªÉn th·ªã dictionary output theo ƒë√∫ng format y√™u c·∫ßu
        st.json(result_dict)

    st.subheader("L·ªãch s·ª≠ ph√¢n lo·∫°i")
    # Hi·ªÉn th·ªã 50 b·∫£n ghi m·ªõi nh·∫•t theo y√™u c·∫ßu
    history = fetch_history(limit=50)
    if history:
        st.table(history)
    else:
        st.info("Ch∆∞a c√≥ l·ªãch s·ª≠. H√£y nh·∫≠p c√¢u ƒë·ªÉ b·∫Øt ƒë·∫ßu.")


if __name__ == "__main__":
    main()

